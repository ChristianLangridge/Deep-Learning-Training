{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55011527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries, downloading and loading training set and test set of MNIST dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "MNIST_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80210df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN architecture parameters\n",
    "#MNIST images are all 28x28 pixels\n",
    "img_size = 28\n",
    "\n",
    "#Defining forward propagation class\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(64,128,kernel_size=5, padding = 2)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive = nn.AdaptiveAvgPool2d((2, 2))  \n",
    "    \n",
    "        self.fc1 = nn.Linear(128*2*2, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        x = self.adaptive(x)   \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the CNN model with the training set\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.ToTensor()\n",
    "MNIST_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "#How many images been passed through at once (minimize with low RAM/memory), then loaded and shuffled with each epoch\n",
    "img_size = 28\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(MNIST_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Negative log likelihood loss function, better when using log_softmax in the output layer\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "#How many times the entire training set is passed through the network (usually 50-200 for medium-sized datasets)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):    \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #Reset gradients to zero before each backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}  Batch {batch_idx+1}/{len(train_loader)}  loss={loss.item():.4f}\", end='\\r', flush=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ce2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing a different data loading strategy \n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "MNIST_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "img_size = 28\n",
    "batch_size = 10\n",
    "net = Net()\n",
    "\n",
    "epochs = 2\n",
    "#Reset gradients to zero before each backpropagation\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(MNIST_train), batch_size):\n",
    "        items = [MNIST_train[j] for j in range(i, min(i+batch_size, len(MNIST_train)))]\n",
    "        images = torch.stack([it[0] for it in items], dim=0).to(device)   # it[0] = image tensor\n",
    "        labels = torch.tensor([it[1] for it in items], dtype=torch.long).to(device)  # it[1] = label ints\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"EPOCH {epoch+1}, fraction complete: {i/len(MNIST_train):.4f}\", end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79730e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
